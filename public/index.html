<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Alexatron AI - Voice Activated</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <style>
        body { background: #0f172a; color: white; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; margin: 0; transition: background 0.5s; }
        h1 { letter-spacing: 5px; color: #3b82f6; text-shadow: 0 0 10px rgba(59, 130, 246, 0.5); }
        
        #recordBtn { width: 120px; height: 120px; border-radius: 50%; border: none; background: #1e293b; color: #3b82f6; font-size: 2.5rem; cursor: pointer; transition: 0.4s; box-shadow: 0 0 15px rgba(0,0,0,0.5); }
        
        /* State Colors */
        .listening-wake #recordBtn { color: #10b981; border: 2px solid #10b981; } 
        .recording #recordBtn { background: #ef4444; color: white; animation: pulse 1.5s infinite; }
        .processing #recordBtn { color: #f59e0b; animation: spin 2s infinite linear; }
        .speaking #recordBtn { background: #3b82f6; color: white; box-shadow: 0 0 30px #3b82f6; }

        #status { margin-top: 30px; font-size: 1.1rem; color: #94a3b8; text-align: center; font-weight: 300; }
        #transcript-preview { margin-top: 15px; font-style: italic; color: #64748b; font-size: 0.9rem; min-height: 1.2rem; }
        
        @keyframes pulse { 0% { transform: scale(1); } 50% { transform: scale(1.05); } 100% { transform: scale(1); } }
        @keyframes spin { 100% { transform: rotate(360deg); } }
    </style>
</head>
<body class="listening-wake">

    <h1>ALEXATRON</h1>
    <button id="recordBtn"><i class="fas fa-microphone"></i></button>
    <div id="status">Click the mic once, then say "Computer" or "AI"</div>
    <div id="transcript-preview"></div>

    <script>
        const recordBtn = document.getElementById('recordBtn');
        const status = document.getElementById('status');
        const preview = document.getElementById('transcript-preview');
        const body = document.body;
        
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        const synth = window.speechSynthesis;

        // Configuration
        const WAKE_WORDS = ["computer", "ai"]; 
        let isActiveCommand = false;
        let isAudioUnlocked = false;

        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'en-US';

        // Auto-start listening
        window.onload = () => {
            try { recognition.start(); } catch(e) {}
        };

        recognition.onresult = async (event) => {
            let interimTranscript = '';
            let finalTranscript = '';

            for (let i = event.resultIndex; i < event.results.length; ++i) {
                let text = event.results[i][0].transcript.toLowerCase().trim();
                if (event.results[i].isFinal) {
                    finalTranscript += text;
                } else {
                    interimTranscript += text;
                }
            }

            preview.textContent = interimTranscript || finalTranscript;

            if (!isActiveCommand) {
                // Wake word check
                const heard = (interimTranscript + " " + finalTranscript).split(" ");
                if (WAKE_WORDS.some(wake => heard.includes(wake))) {
                    triggerCommandMode();
                }
            } else if (finalTranscript !== '') {
                recognition.stop(); 
                getAIResponse(finalTranscript);
            }
        };

        function triggerCommandMode() {
            isActiveCommand = true;
            body.className = 'recording';
            status.textContent = "Listening to your command...";
            
            // Beep feedback
            const ctx = new (window.AudioContext || window.webkitAudioContext)();
            const osc = ctx.createOscillator();
            osc.type = 'sine';
            osc.frequency.setValueAtTime(600, ctx.currentTime);
            osc.connect(ctx.destination);
            osc.start();
            osc.stop(ctx.currentTime + 0.1);
        }

        async function getAIResponse(text) {
            body.className = 'processing';
            status.textContent = "Alexatron is thinking...";
            
            try {
                const response = await fetch('/ask-alexatron', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ message: text })
                });
                const data = await response.json();
                speak(data.reply);
            } catch (err) {
                resetToWakeMode();
            }
        }

        function speak(text) {
            synth.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'en-US';

            // Voice selection
            const voices = synth.getVoices();
            const femaleVoice = voices.find(v => v.name.includes("Google US English") || v.name.includes("Female"));
            if (femaleVoice) utterance.voice = femaleVoice;

            utterance.onstart = () => {
                body.className = 'speaking';
                status.textContent = text;
            };

            utterance.onend = () => { resetToWakeMode(); };
            synth.speak(utterance);
        }

        function resetToWakeMode() {
            isActiveCommand = false;
            body.className = 'listening-wake';
            status.textContent = 'Say "Computer" or "AI" to start';
            preview.textContent = "";
            try { recognition.start(); } catch(e) {}
        }

        recognition.onend = () => {
            if (!isActiveCommand) {
                try { recognition.start(); } catch(e) {}
            }
        };

        // Important: First click unlocks audio for the whole session
        recordBtn.addEventListener('click', () => {
            if(!isAudioUnlocked) {
                synth.speak(new SpeechSynthesisUtterance("System online."));
                isAudioUnlocked = true;
            }
            triggerCommandMode();
        });
    </script>
</body>
</html>
